{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import os\n",
    "import ipaddress\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge les données et on encode les variable catégorielles, on modifie les labels de sortie pour avoir 'none' et 'malveillant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.read_csv(\"../data/final/Credential_Access.csv\")\n",
    "df1=pd.read_csv(\"../data/final/Defense_Evasion.csv\")\n",
    "df2=pd.read_csv(\"../data/final/Discovery.csv\")\n",
    "df3=pd.read_csv(\"../data/final/Exfiltration.csv\")\n",
    "df4=pd.read_csv(\"../data/final/Initial_Access.csv\")\n",
    "df5=pd.read_csv(\"../data/final/none.csv\")\n",
    "df6=pd.read_csv(\"../data/final/Persistence.csv\")\n",
    "df7=pd.read_csv(\"../data/final/Privilege_Escalation.csv\")\n",
    "df8=pd.read_csv(\"../data/final/Reconnaissance.csv\")\n",
    "listeDatasets=[df0,df1,df2,df3,df4,df5,df6,df7,df8]\n",
    "\n",
    "categorical_columns = ['conn_state', 'protocol', 'service', 'history', 'label_tactic']\n",
    "  \n",
    "#Gestion des dates\n",
    "for i in range(len(listeDatasets)):\n",
    "    df=listeDatasets[i]\n",
    "\n",
    "     # Modifier la colonne\n",
    "    df['label_tactic'] = df['label_tactic'].apply(lambda x: \"malveillant\" if x != \"none\" else x)\n",
    "\n",
    "    df['ts'] = pd.to_datetime(df['ts'], unit='s')\n",
    "    df['year'] = df['ts'].dt.year\n",
    "    df['month'] = df['ts'].dt.month\n",
    "    df['day'] = df['ts'].dt.day\n",
    "    df['hour'] = df['ts'].dt.hour\n",
    "    df['minute'] = df['ts'].dt.minute\n",
    "    df['seconde'] = df['ts'].dt.second\n",
    "    df['dayofweek'] = df['ts'].dt.dayofweek  # 0=lundi, 6=dimanche\n",
    "\n",
    "    # Caractéristiques cycliques pour l'heure (pour préserver la nature cyclique)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
    "\n",
    "    # Caractéristiques cycliques pour le jour de la semaine\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['dayofweek']/7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['dayofweek']/7)\n",
    "\n",
    "    # Trier par timestamp pour calculer les différences temporelles\n",
    "    df = df.sort_values('ts')\n",
    "    df['time_since_last'] = df['ts'].diff().dt.total_seconds()\n",
    "\n",
    "    # Remplacer la première valeur NaN par 0 ou une autre valeur appropriée\n",
    "    df['time_since_last'] = df['time_since_last'].fillna(0)\n",
    "\n",
    "    df=df.drop(['ts'], axis=1)\n",
    "\n",
    "    #Gestion des adresses IP\n",
    "    df['src_ip'] = df['src_ip'].apply(lambda x: int(ipaddress.ip_address(x)))\n",
    "    df['dest_ip'] = df['dest_ip'].apply(lambda x: int(ipaddress.ip_address(x)))\n",
    "    \n",
    "    #Une IPV6 est un trop grand nombre, on ne peut pas le mettre en entier\n",
    "    #On normalise donc les ip en divisant par la plus grande valeur possible (pour etre entre 0 et 1)\n",
    "    df['src_ip'] = df['src_ip']/(2**128 - 1) # 2^128 est le max pour IPv6 car codée sur 128 bits\n",
    "    df['dest_ip'] = df['dest_ip']/(2**128 - 1)\n",
    "\n",
    "    df['src_ip']=df['src_ip'].astype(float)\n",
    "    df['dest_ip']=df['dest_ip'].astype(float)\n",
    "\n",
    "    listeDatasets[i]=df\n",
    "# Créer et stocker les encodeurs\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Collecter toutes les valeurs uniques de TOUS les datasets\n",
    "    all_values = pd.concat([df[col] for df in listeDatasets]).unique()\n",
    "    \n",
    "    # Créer et ajuster l'encodeur sur toutes les valeurs possibles\n",
    "    encoders[col] = LabelEncoder().fit(all_values)\n",
    "    \n",
    "    # Appliquer l'encodeur à chaque dataset\n",
    "    for df in listeDatasets:\n",
    "        df[col] = encoders[col].transform(df[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage de la structure d'un dataset encodé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['conn_state', 'duration', 'local_orig', 'local_resp', 'protocol',\n",
      "       'service', 'history', 'src_ip', 'src_port', 'orig_bytes', 'orig_pkts',\n",
      "       'orig_ip_bytes', 'dest_ip', 'dest_port', 'resp_bytes', 'resp_pkts',\n",
      "       'resp_ip_bytes', 'missed_bytes', 'label_tactic', 'year', 'month', 'day',\n",
      "       'hour', 'minute', 'seconde', 'dayofweek', 'hour_sin', 'hour_cos',\n",
      "       'dow_sin', 'dow_cos', 'time_since_last'],\n",
      "      dtype='object')\n",
      "291    7.067394e-30\n",
      "318    7.067402e-30\n",
      "279    7.067397e-30\n",
      "268    7.067402e-30\n",
      "253    7.067402e-30\n",
      "Name: dest_ip, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(listeDatasets[1].columns)\n",
    "print(listeDatasets[7][\"dest_ip\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1712479, 31)\n",
      "(428126, 31)\n",
      "Index(['conn_state', 'duration', 'local_orig', 'local_resp', 'protocol',\n",
      "       'service', 'history', 'src_ip', 'src_port', 'orig_bytes', 'orig_pkts',\n",
      "       'orig_ip_bytes', 'dest_ip', 'dest_port', 'resp_bytes', 'resp_pkts',\n",
      "       'resp_ip_bytes', 'missed_bytes', 'label_tactic', 'year', 'month', 'day',\n",
      "       'hour', 'minute', 'seconde', 'dayofweek', 'hour_sin', 'hour_cos',\n",
      "       'dow_sin', 'dow_cos', 'time_since_last'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Diviser chaque dataset en train/test (80/20)\n",
    "train_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "for df in listeDatasets:\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_dfs.append(train_df)\n",
    "    test_dfs.append(test_df)\n",
    "\n",
    "#Concaténer les ensembles\n",
    "combined_train = pd.concat(train_dfs)\n",
    "combined_test = pd.concat(test_dfs)\n",
    "\n",
    "print(combined_train.shape)\n",
    "print(combined_test.shape)\n",
    "print(combined_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1268782, number of negative: 443697\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2094\n",
      "[LightGBM] [Info] Number of data points in the train set: 1712479, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.740904 -> initscore=1.050671\n",
      "[LightGBM] [Info] Start training from score 1.050671\n"
     ]
    }
   ],
   "source": [
    "features = ['conn_state', 'duration', 'local_orig', 'local_resp', 'protocol',\n",
    "       'service', 'history','src_ip',  'src_port', 'orig_bytes', 'orig_pkts',\n",
    "       'orig_ip_bytes', 'dest_ip', 'dest_port', 'resp_bytes', 'resp_pkts',\n",
    "       'resp_ip_bytes', 'missed_bytes', 'year', 'month', 'day',\n",
    "       'hour', 'minute', 'seconde', 'dayofweek', 'hour_sin', 'hour_cos',\n",
    "       'dow_sin', 'dow_cos', 'time_since_last']\n",
    "\n",
    "label='label_tactic'\n",
    "\n",
    "# Préparer X et y\n",
    "X_train = combined_train[features]\n",
    "y_train = combined_train[label]\n",
    "X_test = combined_test[features]\n",
    "y_test = combined_test[label]\n",
    "\n",
    "# Créer les datasets LightGBM\n",
    "categorical_indices = [features.index(col) for col in categorical_columns[:-1] ]#On recupere l'index de chaque colonne catégorielle (sauf le label)\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_indices)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "\n",
    "# 9. Paramètres LightGBM\n",
    "num_classes = len(encoders['label_tactic'].classes_)\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': num_classes,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "# 10. Entraîner le modèle\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=100,\n",
    "    valid_sets=[test_data],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 11. Évaluer le modèle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m gbm\u001b[38;5;241m.\u001b[39mpredict(X_test, num_iteration\u001b[38;5;241m=\u001b[39mgbm\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[1;32m----> 3\u001b[0m y_pred_class \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Reconvertir en labels textuels pour l'évaluation\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred_labels \u001b[38;5;241m=\u001b[39m encoders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_tactic\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39minverse_transform(y_pred_class)\n",
      "File \u001b[1;32mc:\\Users\\aurel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1229\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aurel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# 11. Évaluer le modèle\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Reconvertir en labels textuels pour l'évaluation\n",
    "y_pred_labels = encoders['label_tactic'].inverse_transform(y_pred_class)\n",
    "y_test_labels = encoders['label_tactic'].inverse_transform(y_test)\n",
    "\n",
    "# Afficher les résultats\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm=confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "labels = np.unique(y_test_labels)\n",
    "\n",
    "# Afficher sous forme de heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels , yticklabels=labels)\n",
    "#annot= affichage des valeurs dans les carrés  fmt = formatage des valeurs, d = entier (par exemple si c'est 0.87, il sera affiché 1).\n",
    "\n",
    "# Ajouter les labels APRÈS avoir tracé la heatmap\n",
    "ax.set_xlabel('Prédictions', fontsize=12)\n",
    "ax.set_ylabel('Vraies étiquettes', fontsize=12)\n",
    "ax.set_title('Matrice de Confusion', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "# Sauvegarder le modèle et les encodeurs\n",
    "import pickle\n",
    "model_package = {\n",
    "    'model': gbm,\n",
    "    'encoders': encoders,\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "with open('lightgbm_model_package.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
